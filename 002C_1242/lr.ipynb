{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f8f2b-1798-4224-82ac-da9a6cf943b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 version: 4.6.0\n",
      "pandas version: 2.1.4\n",
      "numpy version: 1.26.3\n",
      "matplotlib version: 3.8.0\n",
      "seaborn version: 0.12.2\n",
      "missingno version: 0.4.2\n",
      "sklearn version: 1.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import tarfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot as mmult\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "import warnings\n",
    "\n",
    "# Print versions\n",
    "print(\"cv2 version:\", cv2.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"matplotlib version:\", plt.matplotlib.__version__)\n",
    "print(\"seaborn version:\", sns.__version__)\n",
    "print(\"missingno version:\", msno.__version__)\n",
    "print(\"sklearn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2cbe16-171f-4cab-8021-98008e3f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality = fetch_openml(name='wine-quality-red', version=1, parser='auto')\n",
    "X = wine_quality.data\n",
    "Y = wine_quality.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e265b1-3000-4928-b1c5-b3dbb604c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(X, Y):\n",
    "    \"\"\"\n",
    "    Removing rows with missing values.\n",
    "    \"\"\"\n",
    "    missing_values_count_X = X.isnull().sum()\n",
    "    missing_values_count_Y = Y.isnull().sum()\n",
    "\n",
    "    # Print warning if missing values exist in X or Y\n",
    "    if missing_values_count_X.sum() > 0 or missing_values_count_Y > 0:\n",
    "        print(\"Warning: Input data contains missing values!\")\n",
    "        if missing_values_count_X.sum() > 0:\n",
    "            print(f\"Missing values in X: {missing_values_count_X.sum()}\")\n",
    "        if missing_values_count_Y > 0:\n",
    "            print(f\"Missing values in Y: {missing_values_count_Y}\")\n",
    "        print()\n",
    "\n",
    "        # Remove rows with missing values\n",
    "        cleaned_data = X.dropna()\n",
    "        Y_cleaned = Y.loc[cleaned_data.index]\n",
    "\n",
    "        # Reset index for X\n",
    "        X_cleaned = cleaned_data.reset_index(drop=True)\n",
    "        Y_cleaned = Y_cleaned.reset_index(drop=True)\n",
    "    else:\n",
    "        X_cleaned = X\n",
    "        Y_cleaned = Y\n",
    "\n",
    "    return X_cleaned, Y_cleaned\n",
    "\n",
    "X_cleaned, Y_cleaned = handle_missing_values(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9b3b47-9c35-47b8-aed8-b0df8446a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_same_number_rows - True\n"
     ]
    }
   ],
   "source": [
    "def is_same_number_rows(X, Y):\n",
    "    if isinstance(Y, pd.Series):\n",
    "        Y = pd.DataFrame(Y)\n",
    "    return X.shape[0] == Y.shape[0]\n",
    "print(f'is_same_number_rows - {is_same_number_rows(X_cleaned, Y_cleaned)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e56df3-281b-4570-a22c-f9b3d6d4d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, Y, label='Dataset', test_size=0.33, random_state=33, cv=5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    model = RandomForestClassifier(random_state=random_state)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "    \n",
    "    print(f\"{label} Cross-Validation Scores:\", scores)\n",
    "    print(f\"{label} Mean Score:\", scores.mean())\n",
    "    print()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635bfe99-bb13-485e-a496-42ccd76f201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 10 & test_size: 0.3 Cross-Validation Scores: [0.67857143 0.69642857 0.63392857 0.65625    0.68609865]\n",
      "PCA 10 & test_size: 0.3 Mean Score: 0.6702554452274183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = evaluate_model(X_cleaned, Y_cleaned, f'PCA 10 & test_size: {test_size}', test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d0d174-b031-4f1e-a87e-fc27d1a8b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_intercept(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_intercept=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_intercept(X) if add_intercept else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520c36ab-13c2-4f9d-843f-4bcbb313ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_intercept=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_intercept(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd64badc-cee4-4269-894b-007ebd753603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_intercept=False).ravel() # get y difference\n",
    "        # gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = np.mean(X * ydiff.values[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "\n",
    "        return gradient.reshape(self.w_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c47a87-d039-43a5-8cd1-bc6205ca6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e555cd-0937-4fec-8038-68fe07807e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[-1.45432965e-03 -1.18119713e-01  1.39371979e-01 -3.81536705e-02\n",
      "   9.06825276e-02  1.34509130e-02 -4.91475036e-02 -3.31481763e-02\n",
      "  -1.20810866e-03  2.54739563e-02 -3.22423224e-02 -2.55328269e-01]\n",
      " [ 3.38519293e-02 -3.39633977e-01  2.86163892e-01 -1.66800376e-01\n",
      "   2.68078961e-01 -1.16778797e-02 -2.72381031e-01 -7.55762883e-01\n",
      "   3.36574317e-02  2.02793969e-01 -9.83362286e-02 -1.54341591e-01]\n",
      " [ 3.14323323e-01  5.15845869e-01  1.04436854e+00 -4.64736768e-01\n",
      "  -3.14902734e-01  1.37080936e-01 -3.35854868e+00  9.78120731e-01\n",
      "   3.18376287e-01  1.01525532e+00 -5.84115861e-01 -4.60110580e+00]\n",
      " [-5.03777114e-02  9.00197174e-02 -5.75357001e-01  1.91315229e-01\n",
      "  -1.09370557e+00 -3.18439228e-02  2.39272077e+00 -4.84025928e-01\n",
      "  -5.13516620e-02 -1.78933587e-01  3.29475702e-01  1.97475380e+00]\n",
      " [-4.58353040e-01 -8.61309727e-01 -9.06891774e-01  4.57168544e-01\n",
      "   3.55602060e-01 -9.83622481e-02 -7.92311752e-01 -2.72254522e+00\n",
      "  -4.59634489e-01 -1.62097638e+00  2.02773777e-01  4.77193126e-01]\n",
      " [-6.65244422e-02 -4.59152441e-01 -8.23728656e-02  4.36748642e-02\n",
      "   2.23557554e-02 -1.54264857e-02 -8.23010979e-02 -8.67797344e-03\n",
      "  -6.69482629e-02 -2.38422103e-01  3.60335483e-02  1.28951619e-01]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(0.1,500)\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6ec7e4-0207-4b9c-8920-716643631c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.40208333333333335\n"
     ]
    }
   ],
   "source": [
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035ddb3-a16d-4b24-818d-c6e4f450f5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e52887-9471-4719-b865-3748816e41c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01e146-5eab-447b-bf36-6d07cd127d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (002C_1242)",
   "language": "python",
   "name": "002c_1242"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
